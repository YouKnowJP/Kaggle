{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87aee71d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:59:02.779005Z",
     "iopub.status.busy": "2024-11-27T04:59:02.778485Z",
     "iopub.status.idle": "2024-11-27T04:59:07.506757Z",
     "shell.execute_reply": "2024-11-27T04:59:07.505226Z"
    },
    "papermill": {
     "duration": 4.736563,
     "end_time": "2024-11-27T04:59:07.509731",
     "exception": false,
     "start_time": "2024-11-27T04:59:02.773168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7677914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:59:07.521807Z",
     "iopub.status.busy": "2024-11-27T04:59:07.520840Z",
     "iopub.status.idle": "2024-11-27T04:59:08.628023Z",
     "shell.execute_reply": "2024-11-27T04:59:08.626782Z"
    },
    "papermill": {
     "duration": 1.117006,
     "end_time": "2024-11-27T04:59:08.630563",
     "exception": false,
     "start_time": "2024-11-27T04:59:07.513557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"/kaggle/input/playground-series-s4e11/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/playground-series-s4e11/test.csv\")\n",
    "original_df = pd.read_csv(\"/kaggle/input/depression-surveydataset-for-analysis/final_depression_dataset_1.csv\")\n",
    "\n",
    "# Retain the test IDs for submission\n",
    "test_ids = test_df[\"id\"]\n",
    "\n",
    "# Prepare the data\n",
    "original_df[\"Depression\"] = original_df[\"Depression\"].map({\"Yes\": 1, \"No\": 0})\n",
    "full_train = pd.concat([train_df, original_df], ignore_index=True)\n",
    "full_train = full_train.drop([\"id\"], axis=1)\n",
    "test_df = test_df.drop([\"id\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327502d",
   "metadata": {
    "papermill": {
     "duration": 0.002888,
     "end_time": "2024-11-27T04:59:08.636771",
     "exception": false,
     "start_time": "2024-11-27T04:59:08.633883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "In this section of the code, we create additional features for the dataset to enhance the predictive power of machine learning models. These new features are designed based on existing columns by combining them in meaningful ways or applying mathematical operations. Here's a breakdown of the newly engineered features:\n",
    "\n",
    "#### Feature Creation\n",
    "\n",
    "1. **satisfaction_by_work**  \n",
    "   The ratio of `Work Pressure` to `Job Satisfaction`.  \n",
    "   Formula:  \n",
    "   `Satisfaction by Work = Work Pressure / (Job Satisfaction + 1e-8)`  \n",
    "   The small constant `1e-8` is added to avoid division by zero.\n",
    "\n",
    "2. **satisfaction_by_study**  \n",
    "   The ratio of `Academic Pressure` to `Study Satisfaction`.  \n",
    "   Formula:  \n",
    "   `Satisfaction by Study = Academic Pressure / (Study Satisfaction + 1e-8)`\n",
    "\n",
    "3. **age_work_satisfaction**  \n",
    "   The ratio of `Age` to `Job Satisfaction`.  \n",
    "   Formula:  \n",
    "   `Age to Work Satisfaction = Age / (Job Satisfaction + 1e-8)`\n",
    "\n",
    "4. **cgpa_study**  \n",
    "   The ratio of `CGPA` to `Academic Pressure`.  \n",
    "   Formula:  \n",
    "   `CGPA to Study Pressure = CGPA / (Academic Pressure + 1e-8)`\n",
    "\n",
    "5. **work_to_financial_stress_ratio**  \n",
    "   The ratio of `Work Pressure` to `Financial Stress`.  \n",
    "   Formula:  \n",
    "   `Work to Financial Stress Ratio = Work Pressure / (Financial Stress + 1e-8)`\n",
    "\n",
    "6. **academic_to_financial_stress_ratio**  \n",
    "   The ratio of `Academic Pressure` to `Financial Stress`.  \n",
    "   Formula:  \n",
    "   `Academic to Financial Stress Ratio = Academic Pressure / (Financial Stress + 1e-8)`\n",
    "\n",
    "7. **normalized_work_stress**  \n",
    "   A normalized measure of `Work Pressure` relative to `Job Satisfaction`.  \n",
    "   Formula:  \n",
    "   `Normalized Work Stress = Work Pressure / (Job Satisfaction + 1e-8)`\n",
    "\n",
    "8. **normalized_academic_stress**  \n",
    "   A normalized measure of `Academic Pressure` relative to `Study Satisfaction`.  \n",
    "   Formula:  \n",
    "   `Normalized Academic Stress = Academic Pressure / (Study Satisfaction + 1e-8)`\n",
    "\n",
    "9. **age_cgpa_interaction**  \n",
    "   The interaction between `Age` and `CGPA`. This could capture patterns where both age and academic performance (CGPA) together influence the target variable.  \n",
    "   Formula:  \n",
    "   `Age CGPA Interaction = Age * CGPA`\n",
    "\n",
    "10. **total_satisfaction**  \n",
    "   The sum of `Study Satisfaction` and `Job Satisfaction`.  \n",
    "   Formula:  \n",
    "   `Total Satisfaction = Study Satisfaction + Job Satisfaction`\n",
    "\n",
    "11. **total_stress**  \n",
    "   The sum of `Academic Pressure` and `Work Pressure`.  \n",
    "   Formula:  \n",
    "   `Total Stress = Academic Pressure + Work Pressure`\n",
    "\n",
    "12. **is_profession_missing**  \n",
    "   A binary feature indicating if the `Profession` column has a missing value (NaN).  \n",
    "   Formula:  \n",
    "   `Is Profession Missing = Profession.isna().astype(int)`\n",
    "\n",
    "13. **is_cgpa_missing**  \n",
    "   A binary feature indicating if the `CGPA` column has a missing value (NaN).  \n",
    "   Formula:  \n",
    "   `Is CGPA Missing = CGPA.isna().astype(int)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cbbbe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:59:08.644940Z",
     "iopub.status.busy": "2024-11-27T04:59:08.644398Z",
     "iopub.status.idle": "2024-11-27T04:59:08.857507Z",
     "shell.execute_reply": "2024-11-27T04:59:08.856358Z"
    },
    "papermill": {
     "duration": 0.220493,
     "end_time": "2024-11-27T04:59:08.860396",
     "exception": false,
     "start_time": "2024-11-27T04:59:08.639903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def new_feats(df):\n",
    "    df = (\n",
    "        df.assign(\n",
    "            satisfaction_by_work=df[\"Work Pressure\"] / (df[\"Job Satisfaction\"] + 1e-8),\n",
    "            satisfaction_by_study=df[\"Academic Pressure\"] / (df[\"Study Satisfaction\"] + 1e-8),\n",
    "            age_work_satisfaction=df[\"Age\"] / (df[\"Job Satisfaction\"] + 1e-8),\n",
    "            cgpa_study=df[\"CGPA\"] / (df[\"Academic Pressure\"] + 1e-8),\n",
    "            work_to_financial_stress_ratio=df[\"Work Pressure\"] / (df[\"Financial Stress\"] + 1e-8),\n",
    "            academic_to_financial_stress_ratio=df[\"Academic Pressure\"] / (df[\"Financial Stress\"] + 1e-8),\n",
    "            normalized_work_stress=df[\"Work Pressure\"] / (df[\"Job Satisfaction\"] + 1e-8),\n",
    "            normalized_academic_stress=df[\"Academic Pressure\"] / (df[\"Study Satisfaction\"] + 1e-8),\n",
    "            age_cgpa_interaction=df[\"Age\"] * df[\"CGPA\"],\n",
    "            total_satisfaction=df[\"Study Satisfaction\"] + df[\"Job Satisfaction\"],\n",
    "            total_stress=df[\"Academic Pressure\"] + df[\"Work Pressure\"],\n",
    "            is_profession_missing=df[\"Profession\"].isna().astype(int),\n",
    "            is_cgpa_missing=df[\"CGPA\"].isna().astype(int),\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "\n",
    "full_train = new_feats(full_train).copy()\n",
    "test_df = new_feats(test_df).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8720d2",
   "metadata": {
    "papermill": {
     "duration": 0.003131,
     "end_time": "2024-11-27T04:59:08.867781",
     "exception": false,
     "start_time": "2024-11-27T04:59:08.864650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Code Explanation: Handling Missing Values and Encoding Categorical Features\n",
    "\n",
    "The code below performs two main tasks:\n",
    "\n",
    "1. **Identifying Numerical and Categorical Features**\n",
    "2. **Handling Missing Values and Encoding Categorical Data**\n",
    "\n",
    "#### 1. **Identifying Numerical and Categorical Features**\n",
    "\n",
    "```python\n",
    "num_feats = full_train.select_dtypes(include=\"float64\").columns\n",
    "obj_feats = full_train.select_dtypes(include=\"object\").columns\n",
    "target = \"Depression\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbe567f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:59:08.876136Z",
     "iopub.status.busy": "2024-11-27T04:59:08.875690Z",
     "iopub.status.idle": "2024-11-27T04:59:19.121325Z",
     "shell.execute_reply": "2024-11-27T04:59:19.119806Z"
    },
    "papermill": {
     "duration": 10.25275,
     "end_time": "2024-11-27T04:59:19.123851",
     "exception": false,
     "start_time": "2024-11-27T04:59:08.871101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "num_feats = full_train.select_dtypes(include=\"float64\").columns\n",
    "obj_feats = full_train.select_dtypes(include=\"object\").columns\n",
    "target = \"Depression\"\n",
    "\n",
    "# Handle missing values and encode categorical data\n",
    "for col in obj_feats:\n",
    "    le = LabelEncoder()\n",
    "    combined_data = pd.concat([full_train[col], test_df[col]], axis=0)\n",
    "    le.fit(combined_data.astype(str))\n",
    "    full_train[col] = le.transform(full_train[col].astype(str))\n",
    "    test_df[col] = test_df[col].map(lambda s: le.classes_.tolist().index(s) if s in le.classes_ else -1)\n",
    "\n",
    "for col in num_feats:\n",
    "    full_train[col] = full_train[col].fillna(full_train[col].mean())\n",
    "    test_df[col] = test_df[col].fillna(full_train[col].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aadbb43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:59:19.132195Z",
     "iopub.status.busy": "2024-11-27T04:59:19.131817Z",
     "iopub.status.idle": "2024-11-27T04:59:19.156356Z",
     "shell.execute_reply": "2024-11-27T04:59:19.155192Z"
    },
    "papermill": {
     "duration": 0.031812,
     "end_time": "2024-11-27T04:59:19.158974",
     "exception": false,
     "start_time": "2024-11-27T04:59:19.127162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare training and testing data\n",
    "y = full_train[\"Depression\"]\n",
    "X = full_train.drop([\"Depression\"], axis=1)\n",
    "\n",
    "# Number of splits and repetitions for repeated stacking\n",
    "n_splits = 10\n",
    "n_repeats = 5\n",
    "\n",
    "# Base model hyperparameters\n",
    "cat_params = {\n",
    "    \"iterations\": 715,\n",
    "    \"learning_rate\": 0.05009420761428966,\n",
    "    \"rsm\": 0.5859169200239407,\n",
    "    \"subsample\": 0.7705184727295318,\n",
    "    \"min_data_in_leaf\": 30,\n",
    "    \"depth\": 7,\n",
    "    \"l2_leaf_reg\": 0.004379496536587387,\n",
    "    \"random_strength\": 0.4519161767798322,\n",
    "    \"bootstrap_type\": \"Bernoulli\",\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"random_seed\": 42,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": 190,\n",
    "    \"learning_rate\": 0.09496932234009307,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_weight\": 10,\n",
    "    \"subsample\": 0.9433525544556154,\n",
    "    \"colsample_bytree\": 0.986782619688853,\n",
    "    \"colsample_bynode\": 0.933054684872868,\n",
    "    \"colsample_bylevel\": 0.7217799408248594,\n",
    "    \"reg_lambda\": 6.588710936371029,\n",
    "    \"reg_alpha\": 0.8772425195518072,\n",
    "    \"random_state\": 42,\n",
    "    \"use_label_encoder\": False,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf4eaa",
   "metadata": {
    "papermill": {
     "duration": 0.002915,
     "end_time": "2024-11-27T04:59:19.165146",
     "exception": false,
     "start_time": "2024-11-27T04:59:19.162231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Stacking Predictions Across Repetitions\n",
    "\n",
    "This section implements a stacking ensemble technique where predictions from two base models, XGBoost and CatBoost, are combined to improve model performance. The stacking process is repeated across multiple iterations and cross-validation folds to ensure robustness and reliability in the predictions.\n",
    "\n",
    "#### Initializing Stacking Arrays\n",
    "\n",
    "Before the models are trained, two placeholder arrays are initialized:\n",
    "\n",
    "- **X_stack**: This array stores the predicted probabilities for the training data, where predictions from both XGBoost and CatBoost are saved for each sample.\n",
    "- **test_stack**: This array stores the predicted probabilities for the test dataset, again for both base models.\n",
    "\n",
    "These arrays are updated during the stacking process to collect predictions across repetitions and folds.\n",
    "\n",
    "#### Repeated Stacking with Cross-Validation\n",
    "\n",
    "The stacking process is repeated over several iterations (repetitions), and in each iteration, **Stratified K-Fold cross-validation** is used. This ensures that each fold maintains the distribution of the target variable across the training and validation sets.\n",
    "\n",
    "- **Stratified K-Fold**: This cross-validation technique is applied to split the data into multiple training and validation sets, ensuring that each fold represents the overall distribution of the target variable.\n",
    "- During each fold, both base models (XGBoost and CatBoost) are trained on the training set. Their predicted probabilities for the validation set are added to the stacking arrays. The predictions for each sample are aggregated over the course of the entire repetition.\n",
    "\n",
    "The predictions for the test dataset are also aggregated across all repetitions and folds to provide a final prediction from the ensemble model.\n",
    "\n",
    "By using multiple repetitions and folds, the stacking process helps mitigate overfitting and improves the generalization of the model, resulting in more reliable predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce59db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:59:19.173469Z",
     "iopub.status.busy": "2024-11-27T04:59:19.173078Z",
     "iopub.status.idle": "2024-11-27T06:07:15.977791Z",
     "shell.execute_reply": "2024-11-27T06:07:15.976568Z"
    },
    "papermill": {
     "duration": 4076.817634,
     "end_time": "2024-11-27T06:07:15.986026",
     "exception": false,
     "start_time": "2024-11-27T04:59:19.168392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repetition 1 Progress: 100%|██████████| 10/10 [13:46<00:00, 82.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repetition 2 Progress: 100%|██████████| 10/10 [13:38<00:00, 81.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repetition 3 Progress: 100%|██████████| 10/10 [13:30<00:00, 81.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repetition 4 Progress: 100%|██████████| 10/10 [13:30<00:00, 81.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repetition 5 Progress: 100%|██████████| 10/10 [13:31<00:00, 81.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for stacking predictions across repetitions\n",
    "X_stack = np.zeros((X.shape[0], 2))  # 2 base models: XGBoost and CatBoost\n",
    "test_stack = np.zeros((test_df.shape[0], 2))\n",
    "\n",
    "# Repeated stacking\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"Repetition {repeat + 1}/{n_repeats}\")\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42 + repeat)\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(tqdm(kf.split(X, y), total=n_splits, desc=f\"Repetition {repeat + 1} Progress\")):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        \n",
    "        # Train XGBoost\n",
    "        xgb_model = XGBClassifier(**xgb_params)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        X_stack[valid_idx, 0] += xgb_model.predict_proba(X_valid)[:, 1] / n_repeats\n",
    "        test_stack[:, 0] += xgb_model.predict_proba(test_df)[:, 1] / (n_splits * n_repeats)\n",
    "        \n",
    "        # Train CatBoost\n",
    "        cat_model = CatBoostClassifier(**cat_params)\n",
    "        cat_model.fit(Pool(X_train, y_train, cat_features=X[obj_feats].columns.values))\n",
    "        X_stack[valid_idx, 1] += cat_model.predict_proba(Pool(X_valid, cat_features=X[obj_feats].columns.values))[:, 1] / n_repeats\n",
    "        test_stack[:, 1] += cat_model.predict_proba(Pool(test_df, cat_features=X[obj_feats].columns.values))[:, 1] / (n_splits * n_repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a0fe3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T06:07:16.001182Z",
     "iopub.status.busy": "2024-11-27T06:07:16.000768Z",
     "iopub.status.idle": "2024-11-27T06:07:39.781250Z",
     "shell.execute_reply": "2024-11-27T06:07:39.780074Z"
    },
    "papermill": {
     "duration": 23.791005,
     "end_time": "2024-11-27T06:07:39.783732",
     "exception": false,
     "start_time": "2024-11-27T06:07:15.992727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Train optimized Gradient Boosting meta-model\n",
    "best_params = {\n",
    "    \"n_estimators\": 146,\n",
    "    \"learning_rate\": 0.0298358509190979,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.6920403072473079,\n",
    "    \"max_features\": \"sqrt\",\n",
    "}\n",
    "\n",
    "best_meta_model = GradientBoostingClassifier(random_state=42, **best_params)\n",
    "best_meta_model.fit(X_stack, y)\n",
    "\n",
    "# Save predictions for the test set\n",
    "test_meta_preds = best_meta_model.predict_proba(test_stack)[:, 1]\n",
    "submission_path = \"/kaggle/working/submission.csv\"\n",
    "submission = pd.DataFrame({\"id\": test_ids, \"Depression\": (test_meta_preds > 0.5).astype(int)})\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Predictions saved to {submission_path}\")\n",
    "\n",
    "# Evaluate optimized meta-model\n",
    "meta_preds = best_meta_model.predict_proba(X_stack)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741343b",
   "metadata": {
    "papermill": {
     "duration": 0.006612,
     "end_time": "2024-11-27T06:07:39.797434",
     "exception": false,
     "start_time": "2024-11-27T06:07:39.790822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10008389,
     "sourceId": 84895,
     "sourceType": "competition"
    },
    {
     "datasetId": 5868381,
     "sourceId": 9616093,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4121.187586,
   "end_time": "2024-11-27T06:07:40.626331",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-27T04:58:59.438745",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
